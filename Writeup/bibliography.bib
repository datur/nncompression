@misc{RN20,
   url = {https://nervanasystems.github.io/distiller/index.html},
   year = {2019},
   type = {Web Page}
}

@misc{RN22,
   url = {https://www.bittware.com/resources/cnn/},
   year = {2019},
   type = {Web Page}
}

@misc{RN11,
   volume = {2019},
   number = {08/10},
   url = {https://developer.amazon.com/blogs/alexa/post/a7bb4a16-c86b-4019-b3f9-b0d663b87d30/new-method-for-compressing-neural-networks-better-preserves-accuracy},
   year = {2019},
   type = {Web Page}
}

@article{RN13,
   author = {AHMAD SHAWAHNA, SADIQ M. SAIT, AIMAN EL-MALEH},
   title = {FPGA-based Accelerators of Deep Learning Networks for Learning and Classiﬁcation: A Review},
   year = {2018},
   type = {Journal Article}
}

@article{RN10,
   author = {al, Sian Jin et},
   title = {DeepSZ: A Novel Framework to Compress Deep Neural Networks by Using Error-Bounded Lossy Compression},
   DOI = {10.1145/3307681.3326608},
   url = {https://dx.doi.org/10.1145/3307681.3326608},
   year = {2019},
   type = {Journal Article}
}

@article{RN54,
   author = {Chen, Wenlin and Wilson, James T and Tyree, Stephen and Weinberger, Kilian Q and Chen, Yixin},
   title = {Compressing convolutional neural networks},
   journal = {arXiv preprint arXiv:1506.04449},
   year = {2015},
   type = {Journal Article}
}

@article{RN14,
   author = {Cl´ement Farabet, Cyril Poulet, Jefferson Y. Han, Yann LeCun},
   title = {CNP : AN FPGA-BASED PROCESSOR FOR CONVOLUTIONAL NETWORKS},
   type = {Journal Article}
}

@article{RN16,
   author = {Hajduk, Zbigniew},
   title = {Reconfigurable FPGA implementation of neural networks},
   journal = {Neurocomputing},
   volume = {308},
   pages = {227-234},
   ISSN = {0925-2312},
   DOI = {https://doi.org/10.1016/j.neucom.2018.04.077},
   url = {http://www.sciencedirect.com/science/article/pii/S0925231218305393},
   year = {2018},
   type = {Journal Article}
}

@article{RN19,
   author = {Han, Song and Mao, Huizi and Dally, William J},
   title = {Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
   journal = {arXiv preprint arXiv:1510.00149},
   year = {2015},
   type = {Journal Article}
}

@inproceedings{RN18,
   author = {Han, Song and Pool, Jeff and Tran, John and Dally, William},
   title = {Learning both weights and connections for efficient neural network},
   booktitle = {Advances in neural information processing systems},
   pages = {1135-1143},
   type = {Conference Proceedings}
}

@inproceedings{RN17,
   author = {LeCun, Yann and Denker, John S and Solla, Sara A},
   title = {Optimal brain damage},
   booktitle = {Advances in neural information processing systems},
   pages = {598-605},
   type = {Conference Proceedings}
}

@article{RN21,
   author = {Lee, Yoojin Choi; Mostafa El-Khamy; Jungwon},
   title = {Universal Deep Neural Network Compression},
   type = {Journal Article}
}

@misc{RN23,
   year = {2018},
   type = {Web Page}
}

@misc{RN25,
   month = {2018-06-21},
   url = {https://www.intel.ai/compressing-deep-learning-models-with-neural-network-distiller/},
   year = {2018},
   type = {Web Page}
}

@book{RN12,
   author = {Omondi, Amos R and Rajapakse, Jagath Chandana},
   title = {FPGA implementations of neural networks},
   publisher = {Springer},
   volume = {365},
   year = {2006},
   type = {Book}
}

@inproceedings{RN28,
   author = {Umuroglu, Yaman and Fraser, Nicholas J and Gambardella, Giulio and Blott, Michaela and Leong, Philip and Jahre, Magnus and Vissers, Kees},
   title = {Finn: A framework for fast, scalable binarized neural network inference},
   booktitle = {Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
   publisher = {ACM},
   pages = {65-74},
   ISBN = {1450343546},
   type = {Conference Proceedings}
}

@article{RN27,
   author = {Venieris, Stylianos I and Bouganis, Christos-Savvas},
   title = {fpgaConvNet: A toolflow for mapping diverse convolutional neural networks on embedded FPGAs},
   journal = {arXiv preprint arXiv:1711.08740},
   year = {2017},
   type = {Journal Article}
}


